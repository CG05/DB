{"cells":[{"cell_type":"markdown","metadata":{"id":"TpSbD3tnz1jU"},"source":["# 1. 데이터 읽기"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mean radius</th>\n","      <th>mean texture</th>\n","      <th>mean perimeter</th>\n","      <th>mean area</th>\n","      <th>mean smoothness</th>\n","      <th>mean compactness</th>\n","      <th>mean concavity</th>\n","      <th>mean concave points</th>\n","      <th>mean symmetry</th>\n","      <th>mean fractal dimension</th>\n","      <th>radius error</th>\n","      <th>texture error</th>\n","      <th>perimeter error</th>\n","      <th>area error</th>\n","      <th>smoothness error</th>\n","      <th>compactness error</th>\n","      <th>concavity error</th>\n","      <th>concave points error</th>\n","      <th>symmetry error</th>\n","      <th>fractal dimension error</th>\n","      <th>worst radius</th>\n","      <th>worst texture</th>\n","      <th>worst perimeter</th>\n","      <th>worst area</th>\n","      <th>worst smoothness</th>\n","      <th>worst compactness</th>\n","      <th>worst concavity</th>\n","      <th>worst concave points</th>\n","      <th>worst symmetry</th>\n","      <th>worst fractal dimension</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.3001</td>\n","      <td>0.14710</td>\n","      <td>0.2419</td>\n","      <td>0.07871</td>\n","      <td>1.0950</td>\n","      <td>0.9053</td>\n","      <td>8.589</td>\n","      <td>153.40</td>\n","      <td>0.006399</td>\n","      <td>0.04904</td>\n","      <td>0.05373</td>\n","      <td>0.01587</td>\n","      <td>0.03003</td>\n","      <td>0.006193</td>\n","      <td>25.38</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.1622</td>\n","      <td>0.6656</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.0869</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>0.05667</td>\n","      <td>0.5435</td>\n","      <td>0.7339</td>\n","      <td>3.398</td>\n","      <td>74.08</td>\n","      <td>0.005225</td>\n","      <td>0.01308</td>\n","      <td>0.01860</td>\n","      <td>0.01340</td>\n","      <td>0.01389</td>\n","      <td>0.003532</td>\n","      <td>24.99</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.1238</td>\n","      <td>0.1866</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.1974</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>0.05999</td>\n","      <td>0.7456</td>\n","      <td>0.7869</td>\n","      <td>4.585</td>\n","      <td>94.03</td>\n","      <td>0.006150</td>\n","      <td>0.04006</td>\n","      <td>0.03832</td>\n","      <td>0.02058</td>\n","      <td>0.02250</td>\n","      <td>0.004571</td>\n","      <td>23.57</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.1444</td>\n","      <td>0.4245</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.2414</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>0.09744</td>\n","      <td>0.4956</td>\n","      <td>1.1560</td>\n","      <td>3.445</td>\n","      <td>27.23</td>\n","      <td>0.009110</td>\n","      <td>0.07458</td>\n","      <td>0.05661</td>\n","      <td>0.01867</td>\n","      <td>0.05963</td>\n","      <td>0.009208</td>\n","      <td>14.91</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.2098</td>\n","      <td>0.8663</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.1980</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>0.05883</td>\n","      <td>0.7572</td>\n","      <td>0.7813</td>\n","      <td>5.438</td>\n","      <td>94.44</td>\n","      <td>0.011490</td>\n","      <td>0.02461</td>\n","      <td>0.05688</td>\n","      <td>0.01885</td>\n","      <td>0.01756</td>\n","      <td>0.005115</td>\n","      <td>22.54</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.1374</td>\n","      <td>0.2050</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   mean radius  mean texture  ...  worst fractal dimension  class\n","0        17.99         10.38  ...                  0.11890      0\n","1        20.57         17.77  ...                  0.08902      0\n","2        19.69         21.25  ...                  0.08758      0\n","3        11.42         20.38  ...                  0.17300      0\n","4        20.29         14.34  ...                  0.07678      0\n","\n","[5 rows x 31 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","from sklearn.datasets import load_breast_cancer\n","\n","cancer = load_breast_cancer()\n","df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n","df['class'] = cancer.target\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"3-QF9HKIz3zU"},"source":["# 2. 모델 만들기\n","> voting_classifier(분류기 리스트, voting=\"보팅기법\")으로 선언해주어야 한다."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["정확도 :  0.956140350877193\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.metrics import accuracy_score\n","\n","X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], \n","                                                    df.iloc[:,-1],test_size=0.2,random_state=10)\n","lr = LogisticRegression(max_iter=4000)\n","knn = KNeighborsClassifier()\n","dt = DecisionTreeClassifier()\n","\n","vo = VotingClassifier([('lr', lr), ('knn', knn), ('dt', dt)], voting='soft')\n","vo.fit(X_train, y_train)\n","y_pred = vo.predict(X_test)\n","\n","print('정확도 : ', accuracy_score(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"lNzRDq9_3oLW"},"source":["> 다음과 같은 경고가 나타날 경우 lr의 max_iter의 수치를 올린다.\n","\n",">Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","\n",">Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["클래스 :  <class 'sklearn.linear_model._logistic.LogisticRegression'>\n","LogisticRegression 의 정확도 : 0.956140350877193\n","클래스 :  <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n","KNeighborsClassifier 의 정확도 : 0.9210526315789473\n","클래스 :  <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n","DecisionTreeClassifier 의 정확도 : 0.9210526315789473\n"]}],"source":["for model in [lr, knn, dt]:\n","    print('클래스 : ', model.__class__)\n","    model_name = model.__class__.__name__\n","    model.fit(X_train, y_train)\n","    pred = model.predict(X_test)\n","\n","    acc = accuracy_score(y_test, pred)\n","    print(f'{model_name} 의 정확도 : {acc}')"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["정확도 :  0.9736842105263158\n"]}],"source":["vo = VotingClassifier([('lr', lr), ('knn', knn), ('dt', dt)], voting='hard')\n","vo.fit(X_train, y_train)\n","y_pred = vo.predict(X_test)\n","\n","print('정확도 : ', accuracy_score(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"SZfJmLbTgaMJ"},"source":["# 3. 스케일링을 통한 모델 성능 높이기\n","> 로지스틱 회귀의 경우 데이터를 스케일링하게 되면 성능이 향상됨으로 StandardScaler를 통해 스케일링을 진행해 보자"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["정확도 :  0.9736842105263158\n"]}],"source":["from sklearn.preprocessing import StandardScaler\n","\n","X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], \n","                                                    df.iloc[:,-1], test_size=0.2, random_state=10)\n","lr = LogisticRegression(max_iter=4000)\n","knn = KNeighborsClassifier()\n","dt = DecisionTreeClassifier()\n","\n","vo = VotingClassifier([('lr', lr), ('knn', knn), ('dt', dt)], voting='soft')\n","vo.fit(X_train, y_train)\n","y_pred = vo.predict(X_test)\n","\n","print('정확도 : ', accuracy_score(y_test, y_pred))"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["정확도 : 0.9912280701754386\n"]}],"source":["scaler = StandardScaler()\n","\n","scaler.fit(X_train)\n","X_train_std = scaler.transform(X_train)\n","X_test_std = scaler.transform(X_test)\n","\n","vo = VotingClassifier([('lr',lr), ('knn',knn), ('dt', dt)], voting='soft')\n","\n","vo.fit(X_train_std, y_train)\n","y_pred = vo.predict(X_test_std)\n","\n","print('정확도 :', accuracy_score(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"TwVGF2jv7YU_"},"source":["# 4. 교차검증"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["모델 :  VotingClassifier\n","전체 정확도\n","[0.98245614 0.96491228 0.95614035 0.94736842 0.96460177]\n","평균 정확도 : 0.9630957925787922\n","==============================\n","모델 :  LogisticRegression\n","전체 정확도\n","[0.99122807 0.97368421 0.98245614 0.96491228 0.96460177]\n","평균 정확도 : 0.9753764943331781\n","==============================\n","모델 :  KNeighborsClassifier\n","전체 정확도\n","[0.97368421 0.95614035 0.94736842 0.96491228 0.99115044]\n","평균 정확도 : 0.9666511411271541\n","==============================\n","모델 :  DecisionTreeClassifier\n","전체 정확도\n","[0.95614035 0.90350877 0.92105263 0.88596491 0.92035398]\n","평균 정확도 : 0.9174041297935103\n","==============================\n"]}],"source":["import numpy as np \n","from sklearn.model_selection import cross_val_score\n","\n","for model in [vo, lr, knn, dt]:\n","    scores = cross_val_score(model, np.concatenate((X_train_std, X_test_std)),\n","                             np.concatenate((y_train,y_test)), scoring='accuracy', cv=5)\n","    print('모델 : ',model.__class__.__name__)\n","    print('전체 정확도')\n","    print(scores)\n","    print('평균 정확도 :',np.mean(scores))\n","    print('=' * 30)"]},{"cell_type":"markdown","metadata":{"id":"y3dQCu-GvZE3"},"source":["# 5. 튜닝\n","> 하이퍼 파라미터 설정 시 이전 VotingClassifier에서 설정한 쌍따옴표 안의 문자와 언더바(_) 두 개를 이어서 파라미터를 설정할 수 있다."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","\n","def get_best_params(cost_list, n_neighbors_list, n_depth_list, n_split_list):\n","    params = {\n","        'lr__C':cost_list,\n","        'knn__n_neighbors':n_neighbors_list,\n","        'knn__weights':['uniform', 'distance'],\n","        'knn__metric':['euclidean', 'manhattan', 'minkowski'],\n","        'dt__max_depth':n_depth_list,\n","        'dt__min_samples_split':n_split_list\n","    }\n","\n","    grid_cv = GridSearchCV(vo, param_grid=params, scoring='accuracy', cv=5)\n","    grid_cv.fit(X_train_std, y_train)\n","\n","    print('Best Score : ', grid_cv.best_score_)\n","    print('Best Hyper Parameters :', grid_cv.best_params_)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Score :  0.9736263736263737\n","Best Hyper Parameters : {'dt__max_depth': 11, 'dt__min_samples_split': 2, 'knn__metric': 'manhattan', 'knn__n_neighbors': 1, 'knn__weights': 'distance', 'lr__C': 10}\n"]}],"source":["cost_list = [0.001, 0.01, 0.1, 1, 10]\n","n_neighbors_list = range(1, 100, 10)\n","n_depth_list = range(1, 21, 10)\n","n_split_list = range(2, 50, 10)\n","\n","get_best_params(cost_list, n_neighbors_list, n_depth_list, n_split_list)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Score :  0.9736263736263737\n","Best Hyper Parameters : {'dt__max_depth': 11, 'dt__min_samples_split': 2, 'knn__metric': 'manhattan', 'knn__n_neighbors': 1, 'knn__weights': 'distance', 'lr__C': 5}\n"]}],"source":["# max_depth : 11\n","# min_samples_split : 2\n","# metric : manhattan\n","# n_neighbors : 1\n","# weights : distance\n","# C : 10\n","\n","n_depth_list = range(11, 22, 5)\n","n_split_list = range(2, 12, 3)\n","n_neighbors_list = range(1, 10, 3)\n","cost_list = range(2, 12, 3)\n","\n","get_best_params(cost_list, n_neighbors_list, n_depth_list, n_split_list)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Score :  0.9736263736263737\n","Best Hyper Parameters : {'dt__max_depth': 9, 'dt__min_samples_split': 3, 'knn__metric': 'manhattan', 'knn__n_neighbors': 1, 'knn__weights': 'distance', 'lr__C': 6}\n"]}],"source":["# max_depth : 11\n","# min_samples_split : 2\n","# metric : manhattan\n","# n_neighbors : 1\n","# weights : distance\n","# C : 10\n","\n","\n","# max_depth : 11\n","# sample_split : 2\n","# neighbor : 1\n","# cost : 5\n","\n","n_depth_list = range(8, 14, 1)\n","n_split_list = range(2, 4, 1)\n","n_neighbors_list = range(1, 3, 1)\n","cost_list = range(2, 8, 1)\n","\n","get_best_params(cost_list, n_neighbors_list, n_depth_list, n_split_list)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["정확도 :  0.9736842105263158\n"]}],"source":["lr = LogisticRegression(max_iter=4000, C=6)\n","knn = KNeighborsClassifier(metric='manhattan', weights='distance', n_neighbors=1)\n","dt = DecisionTreeClassifier(max_depth=9, min_samples_split=3)\n","\n","vo = VotingClassifier([('lr', lr), ('knn', knn), ('dt', dt)], voting='soft')\n","\n","vo.fit(X_train_std, y_train)\n","pred = vo.predict(X_test_std)\n","\n","print('정확도 : ', accuracy_score(y_test, pred))"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["모델 :  VotingClassifier\n","전체 정확도\n","[0.99122807 0.97368421 0.96491228 0.95614035 0.95575221]\n","평균 정확도 : 0.9683434249340165\n","==============================\n","모델 :  LogisticRegression\n","전체 정확도\n","[0.99122807 0.96491228 0.98245614 0.95614035 0.9380531 ]\n","평균 정확도 : 0.9665579878900792\n","==============================\n","모델 :  KNeighborsClassifier\n","전체 정확도\n","[0.98245614 0.97368421 0.9122807  0.92982456 0.98230088]\n","평균 정확도 : 0.9561092997981678\n","==============================\n","모델 :  DecisionTreeClassifier\n","전체 정확도\n","[0.93859649 0.9122807  0.92982456 0.92982456 0.90265487]\n","평균 정확도 : 0.9226362366092221\n","==============================\n"]}],"source":["for model in [vo, lr, knn, dt]:\n","    scores = cross_val_score(model, np.concatenate((X_train_std, X_test_std)),\n","                             np.concatenate((y_train,y_test)), scoring='accuracy', cv=5)\n","    print('모델 : ',model.__class__.__name__)\n","    print('전체 정확도')\n","    print(scores)\n","    print('평균 정확도 :',np.mean(scores))\n","    print('=' * 30)"]},{"cell_type":"markdown","metadata":{"id":"17JucVBCEh51"},"source":["> 파라미터는 알고리즘마다 다르게 나타나며 각 알고리즘에 맞는 파라미터를 지정하기 위해 3번에서 VotingClassifier에 적용된 값을 사용하여 lr__C 형식으로 만들게 된다."]}],"metadata":{"colab":{"collapsed_sections":[],"name":"2. 보팅 분류기 실습.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
