{"cells":[{"cell_type":"markdown","metadata":{},"source":["## 패키지 설치\n","```\n","pip install xgboost\n","```"]},{"cell_type":"markdown","metadata":{"id":"6Dq6LfZygYAJ"},"source":["> n_estimators는 생성할 트리의 개수로 400정도를 지정하자. 이 값은 높으면 높을 수록 성능이 향상되지만 그만큼 시간이 오래 걸린다.\n","\n","> learning_rate는 GBM이 학습을 진행할 때마다 적용하는 학습률로 오류 값을 보정해 가는 데 적용되는 계수로 0.1을 사용했으며 작을 수록 오류를 많이 찾을 수 있지만 시간이 오래 걸린다.\n","\n","> Max_depth는 트리의 최대 깊이로 3을 설정했으며 보통 3~10정도를 설정한다.\n","\n","> early_stopping_rounds은 n_estimators가 400임으로 400번의 부스팅을 진행하는 동안 100번의 학습오류가 감소하지 않으면 더 이상 부스팅을 진행하지 않고 종료한다.\n","\n","> eval_set은 evaluation 세트, 즉 검증 세트를 지정하는 것이다.  fit( ) 수행 시 반복적으로 예측 오류값을 줄일 수 있도록 학습이 진행되는데 이때 학습은 학습 데이터로 하되, 예측 오류값 평가는 eval_set로 지정된 검증 세트로 평가하는 방식이다. 학습 데이터로만 예측 오류값을 줄이게 되면 오버 피팅이 될 가능성이 높아 별도의 검증 세트를 지정하여 수행해야 한다.\n","\n","> eval_metric은 검증 함수를 지정할 수 있으며 예측값 가중치 적용을 위해 logloss를 이용했다."]},{"cell_type":"markdown","metadata":{"id":"oLNtxP2-9zF5"},"source":["> 48번까지 수치가 줄다 다시 늘어 난 것을 볼 수 있으며 100회가 지나도 수치는 줄지 않아 멈추게 된다."]},{"cell_type":"markdown","metadata":{"id":"NLyu_-KSEJ2j"},"source":["> 튜닝"]}],"metadata":{"colab":{"name":"8.XGBoost 실습.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
